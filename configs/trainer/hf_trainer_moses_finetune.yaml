bf16: true
bf16_full_eval: true
tf32: true
dataloader_drop_last: true
dataloader_num_workers: 4
dataloader_pin_memory: true
do_eval: false
do_train: true
evaluation_strategy: "steps"
eval_steps: 200
gradient_accumulation_steps: 1
gradient_checkpointing: false
learning_rate: 5e-6
log_on_each_node: false
logging_steps: 1
lr_scheduler_type: "linear"
max_grad_norm: 1.0
num_train_epochs: 2
optim: "adamw_torch"
per_device_eval_batch_size: 1024
per_device_train_batch_size: 1024
save_steps: 1000
save_strategy: "steps"
save_total_limit: 5
torch_compile: false
warmup_steps: 100
weight_decay: 0.01
save_spec_steps: 1000