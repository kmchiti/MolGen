bf16: true
bf16_full_eval: true
tf32: true
dataloader_drop_last: true
dataloader_num_workers: 24
dataloader_pin_memory: true
do_eval: false
do_train: true
evaluation_strategy: "steps"
eval_steps: 10
gradient_accumulation_steps: 1
gradient_checkpointing: false
learning_rate: 4e-4
log_on_each_node: false
logging_steps: 1
lr_scheduler_type: "cosine"
max_grad_norm: 1.0
max_steps: 100000
optim: "adamw_torch"
per_device_eval_batch_size: 2048
per_device_train_batch_size: 2048
save_steps: 1000
save_strategy: "steps"
save_total_limit: 5
torch_compile: false
warmup_ratio: 0.02
weight_decay: 0.01
save_spec_steps: 10000